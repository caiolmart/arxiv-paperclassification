{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PygNodePropPredDataset()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', \n",
    "                                 root='../../data/dataset/',\n",
    "                                 transform=T.ToSparseTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(adj_t=[169343, 169343, nnz=1166243], node_year=[169343, 1], x=[169343, 128], y=[169343, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]),\n",
       " 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]),\n",
       " 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([     0,      0,      0,  ..., 169341, 169342, 169342]),\n",
       "             col=tensor([   411,    640,   1162,  ..., 163274,  27824, 158981]),\n",
       "             size=(169343, 169343), nnz=2315598, density=0.01%)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "data.adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col, _ = data.adj_t.coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   411,    640,   1162,  ..., 163274,  27824, 158981],\n",
       "        [     0,      0,      0,  ..., 169341, 169342, 169342]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.stack([col, row], dim=0)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   411,      0],\n",
       "        [   640,      0],\n",
       "        [  1162,      0],\n",
       "        ...,\n",
       "        [163274, 169341],\n",
       "        [ 27824, 169342],\n",
       "        [158981, 169342]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2315598])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([411,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([411,   0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.t()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.weight.data.fill_(1)\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        x = self.lin(x)\n",
    "        x = F.relu(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=0\n",
    "log_steps=1\n",
    "num_layers=2\n",
    "hidden_channels=50\n",
    "dropout=0.5\n",
    "batch_size=128 * 1024\n",
    "lr=0.005\n",
    "epochs=100\n",
    "eval_steps=2\n",
    "runs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_t = data.adj_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f31ba232970>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(hidden_channels, hidden_channels,\n",
    "             hidden_channels, num_layers,\n",
    "             dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(data.num_nodes, hidden_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LinkPredictor(hidden_channels, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169343, 50)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.size(0), emb.weight.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 3.8116e-03, -1.7777e-04,  2.6052e-03,  ..., -9.5538e-04,\n",
       "         -5.6698e-03,  2.9117e-03],\n",
       "        [ 4.8286e-03,  5.7555e-03,  4.1475e-03,  ...,  2.2556e-03,\n",
       "          2.7162e-03,  4.5704e-03],\n",
       "        [ 1.6921e-03, -1.5087e-03,  3.1802e-03,  ..., -4.9685e-03,\n",
       "         -5.1306e-04, -9.3337e-04],\n",
       "        ...,\n",
       "        [ 4.1685e-03,  3.3565e-03,  3.5653e-03,  ...,  3.1168e-03,\n",
       "         -1.2510e-03, -3.7040e-03],\n",
       "        [-6.9713e-04,  2.8990e-03,  4.6939e-03,  ...,  3.2265e-03,\n",
       "          2.1993e-03,  4.2817e-03],\n",
       "        [ 4.2867e-03, -3.3813e-03,  3.8860e-05,  ...,  2.8638e-03,\n",
       "          5.3680e-04, -6.6582e-05]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.xavier_uniform_(emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_parameters()\n",
    "predictor.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(emb.parameters()) +\n",
    "    list(predictor.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = edge_index.t().to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='sparse')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 1.1344\n",
      "Epoch: 04, Loss: 1.0165\n",
      "Epoch: 06, Loss: 0.9634\n",
      "Epoch: 08, Loss: 0.9285\n",
      "Epoch: 10, Loss: 0.9002\n",
      "Epoch: 12, Loss: 0.8802\n",
      "Epoch: 14, Loss: 0.8650\n",
      "Epoch: 16, Loss: 0.8529\n",
      "Epoch: 18, Loss: 0.8430\n",
      "Epoch: 20, Loss: 0.8351\n",
      "Epoch: 22, Loss: 0.8281\n",
      "Epoch: 24, Loss: 0.8210\n",
      "Epoch: 26, Loss: 0.8151\n",
      "Epoch: 28, Loss: 0.8098\n",
      "Epoch: 30, Loss: 0.8058\n",
      "Epoch: 32, Loss: 0.8020\n",
      "Epoch: 34, Loss: 0.7984\n",
      "Epoch: 36, Loss: 0.7951\n",
      "Epoch: 38, Loss: 0.7913\n",
      "Epoch: 40, Loss: 0.7889\n",
      "Epoch: 42, Loss: 0.7869\n",
      "Epoch: 44, Loss: 0.7848\n",
      "Epoch: 46, Loss: 0.7820\n",
      "Epoch: 48, Loss: 0.7801\n",
      "Epoch: 50, Loss: 0.7777\n",
      "Epoch: 52, Loss: 0.7764\n",
      "Epoch: 54, Loss: 0.7751\n",
      "Epoch: 56, Loss: 0.7732\n",
      "Epoch: 58, Loss: 0.7713\n",
      "Epoch: 60, Loss: 0.7705\n",
      "Epoch: 62, Loss: 0.7693\n",
      "Epoch: 64, Loss: 0.7676\n",
      "Epoch: 66, Loss: 0.7668\n",
      "Epoch: 68, Loss: 0.7659\n",
      "Epoch: 70, Loss: 0.7644\n",
      "Epoch: 72, Loss: 0.7642\n",
      "Epoch: 74, Loss: 0.7616\n",
      "Epoch: 76, Loss: 0.7618\n",
      "Epoch: 78, Loss: 0.7605\n",
      "Epoch: 80, Loss: 0.7595\n",
      "Epoch: 82, Loss: 0.7585\n",
      "Epoch: 84, Loss: 0.7583\n",
      "Epoch: 86, Loss: 0.7572\n",
      "Epoch: 88, Loss: 0.7566\n",
      "Epoch: 90, Loss: 0.7564\n",
      "Epoch: 92, Loss: 0.7560\n",
      "Epoch: 94, Loss: 0.7545\n",
      "Epoch: 96, Loss: 0.7536\n",
      "Epoch: 98, Loss: 0.7529\n",
      "Epoch: 100, Loss: 0.7533\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1 + epochs):\n",
    "    loss = train(model, predictor, emb.weight, adj_t,\n",
    "                 optimizer, batch_size)\n",
    "    \n",
    "    if epoch % eval_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2.3051, 1.0035, 1.9316, 0.9331, 1.0529, 1.3620, 1.0817, 1.0687, 1.7008,\n",
       "         1.2455, 1.2943, 0.9393, 0.9836, 1.1475, 2.3720, 1.0032, 0.9872, 1.0330,\n",
       "         1.1058, 0.9621, 0.9796, 1.0139, 0.9832, 0.8654, 1.1625, 0.9785, 1.1312,\n",
       "         0.9782, 0.9908, 1.0503, 0.8652, 1.0879, 1.1634, 0.9261, 0.9432, 0.9667,\n",
       "         0.9000, 1.0575, 0.9860, 1.0430, 1.0898, 1.1150, 0.9332, 1.1843, 1.0730,\n",
       "         0.9816, 0.9872, 0.9878, 1.3387, 0.9686]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAGE(\n",
       "  (convs): ModuleList(\n",
       "    (0): SAGEConv(50, 50)\n",
       "    (1): SAGEConv(50, 50)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1371, -0.2608, -0.2502,  ..., -0.0919, -0.2886,  0.1582],\n",
       "        [ 0.3281,  0.0854, -0.0218,  ...,  0.0308, -0.0262, -0.1161],\n",
       "        [-0.2098,  0.1723,  0.0692,  ...,  0.0392,  0.0853,  0.1854],\n",
       "        ...,\n",
       "        [-0.0155,  0.0959,  0.1951,  ...,  0.0955, -0.0562,  0.0080],\n",
       "        [-0.0640,  0.0092,  0.0416,  ..., -0.0278,  0.0195,  0.1950],\n",
       "        [-0.1959,  0.1542,  0.3159,  ...,  0.0519,  0.2112, -0.3311]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model(emb.weight, adj_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0323, -0.1698, -0.4031,  ..., -0.4262, -0.9858,  0.3831],\n",
       "        [ 0.6392, -0.3035,  0.1097,  ..., -0.1709, -0.2094,  0.3562],\n",
       "        [ 0.3483, -0.3747,  0.2352,  ..., -0.3968, -0.6598, -0.6173],\n",
       "        ...,\n",
       "        [-0.0883,  0.0505, -0.0584,  ...,  0.3078,  0.0079,  0.1374],\n",
       "        [ 0.2262, -0.0766, -0.3615,  ..., -0.3752, -0.4662,  0.1222],\n",
       "        [ 0.0800, -0.0258,  0.0686,  ..., -0.2138, -0.6644,  0.2232]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9922], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(h[0], h[411])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(h[0], h[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3529, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h[0] * h[2]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5649, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h[0] * h[411]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../models/graphsage_link_pred/full_graphsage_linkpred_30_h.npy', h.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../../models/graphsage_link_pred/30_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(emb, '../../models/graphsage_link_pred/30_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(predictor, '../../models/graphsage_link_pred/30_predictor.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
