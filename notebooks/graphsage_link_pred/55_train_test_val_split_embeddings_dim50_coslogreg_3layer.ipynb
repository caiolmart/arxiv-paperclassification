{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_NUMBER = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PygNodePropPredDataset()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', \n",
    "                                 root='../../data/dataset/',\n",
    "                                 #transform=T.ToSparseTensor()\n",
    "                                 )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 1166243], node_year=[169343, 1], x=[169343, 128], y=[169343, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]),\n",
       " 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]),\n",
       " 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1166243])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([620901, 244106, 151922,  ..., 667426,  64372, 582625])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "idx = torch.randperm(data.edge_index.size(1))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29156, 29156)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val_edges = n_test_edges = int(data.edge_index.size(1) * 0.025)\n",
    "n_val_edges, n_test_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([620901, 244106, 151922,  ..., 406803, 294223, 329780]),\n",
       " tensor([  72465,  954986,  819672,  ...,  383355,  221124, 1049776]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx = idx[:n_val_edges]\n",
    "test_idx = idx[n_val_edges:(n_val_edges + n_test_edges)]\n",
    "val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[126442, 142022,  45460,  ...,  16499,  41597,  64196],\n",
       "        [167681, 104032,  26564,  ...,  76002, 149932, 137760]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_edges = data.edge_index[:, val_idx]\n",
    "test_edges = data.edge_index[:, test_idx]\n",
    "val_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29156"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_edges.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_val_edges = negative_sampling(all_edges, num_nodes=data.x.size(0),\n",
    "                                  num_neg_samples=val_edges.size(1), method='sparse')\n",
    "neg_test_edges = negative_sampling(all_edges, num_nodes=data.x.size(0),\n",
    "                                   num_neg_samples=test_edges.size(1), method='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 620901,  244106,  151922,  ...,  383355,  221124, 1049776])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_idx = torch.cat([val_idx, test_idx])\n",
    "remove_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows(tensor, indices):\n",
    "    mask = torch.ones(tensor.size(1), dtype=torch.bool)\n",
    "    mask[indices] = False\n",
    "    return tensor[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1107931])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index = remove_rows(data.edge_index, remove_idx)\n",
    "data.edge_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(adj_t=[169343, 169343, nnz=1107931], node_year=[169343, 1], x=[169343, 128], y=[169343, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.ToSparseTensor()(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.adj_t = data.adj_t.to_symmetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   411,    640,   1162,  ..., 163274,  27824, 158981],\n",
       "        [     0,      0,      0,  ..., 169341, 169342, 169342]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row, col, _ = data.adj_t.coo()\n",
    "edge_index = torch.stack([col, row], dim=0)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, out_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(out_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, out_channels, bias=True):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.lin = torch.nn.Linear(1, out_channels, bias=bias)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.weight.data.fill_(1)\n",
    "        self.lin.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        cos_sim = torch.sum(\n",
    "            torch.mul(F.normalize(x_i), \n",
    "                      F.normalize(x_j)), \n",
    "            dim=1,\n",
    "            keepdim=True\n",
    "        )\n",
    "        x = self.lin(cos_sim)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=0\n",
    "log_steps=1\n",
    "num_layers=3\n",
    "hidden_channels=50\n",
    "dropout=0.5\n",
    "batch_size=128 * 1024\n",
    "lr=0.005\n",
    "epochs=300\n",
    "eval_steps=5\n",
    "runs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_t = data.adj_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb69a8f2410>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(hidden_channels, hidden_channels,\n",
    "             dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(data.num_nodes, hidden_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LinkPredictor(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8062]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169343, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.size(0), emb.weight.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 3.8116e-03, -1.7777e-04,  2.6052e-03,  ..., -9.5538e-04,\n",
       "         -5.6698e-03,  2.9117e-03],\n",
       "        [ 4.8286e-03,  5.7555e-03,  4.1475e-03,  ...,  2.2556e-03,\n",
       "          2.7162e-03,  4.5704e-03],\n",
       "        [ 1.6921e-03, -1.5087e-03,  3.1802e-03,  ..., -4.9685e-03,\n",
       "         -5.1306e-04, -9.3337e-04],\n",
       "        ...,\n",
       "        [ 4.1685e-03,  3.3565e-03,  3.5653e-03,  ...,  3.1168e-03,\n",
       "         -1.2510e-03, -3.7040e-03],\n",
       "        [-6.9713e-04,  2.8990e-03,  4.6939e-03,  ...,  3.2265e-03,\n",
       "          2.1993e-03,  4.2817e-03],\n",
       "        [ 4.2867e-03, -3.3813e-03,  3.8860e-05,  ...,  2.8638e-03,\n",
       "          5.3680e-04, -6.6582e-05]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.xavier_uniform_(emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_parameters()\n",
    "predictor.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.lin.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(emb.parameters()) +\n",
    "    list(predictor.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = edge_index.t().to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='sparse')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[126442, 142022,  45460,   1964,  59023],\n",
       "        [167681, 104032,  26564,  13902, 105460]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge = val_edges[:, 0:5]\n",
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, predictor, x, adj_t, batch_size, val_edges, test_edges, neg_val_edges, neg_test_edges):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "    \n",
    "    h = model(x, adj_t)\n",
    "    \n",
    "    val_pos_out = predictor(h[val_edges[0]], h[val_edges[1]])\n",
    "    val_pos_loss = -torch.log(val_pos_out + 1e-15).mean()\n",
    "    \n",
    "    val_neg_out = predictor(h[neg_val_edges[0]], h[neg_val_edges[1]])\n",
    "    val_neg_loss = -torch.log(1 - val_neg_out + 1e-15).mean()\n",
    "    \n",
    "    \n",
    "    test_pos_out = predictor(h[test_edges[0]], h[test_edges[1]])\n",
    "    test_pos_loss = -torch.log(test_pos_out + 1e-15).mean()\n",
    "    \n",
    "    test_neg_out = predictor(h[neg_test_edges[0]], h[neg_test_edges[1]])\n",
    "    test_neg_loss = -torch.log(1 - test_neg_out + 1e-15).mean()\n",
    "    \n",
    "    return val_pos_loss + val_neg_loss, test_pos_loss + test_neg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(model, predictor, embedding, epoch):\n",
    "    torch.save(model, f'../../models/graphsage_link_pred/{NB_NUMBER}_model_epoch{epoch:04d}.pt')\n",
    "    torch.save(embedding, f'../../models/graphsage_link_pred/{NB_NUMBER}_embedding_epoch{epoch:04d}.pt')\n",
    "    torch.save(predictor, f'../../models/graphsage_link_pred/{NB_NUMBER}_predictor_epoch{epoch:04d}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(columns=[\n",
    "    'epoch',\n",
    "    'train_loss',\n",
    "    'valid_loss',\n",
    "    'test_loss'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005, Train Loss: 0.9849, Valid loss: 0.9955, Test loss: 0.9949\n",
      "Epoch: 0010, Train Loss: 0.8149, Valid loss: 0.8388, Test loss: 0.8351\n",
      "Epoch: 0015, Train Loss: 0.7035, Valid loss: 0.7395, Test loss: 0.7332\n",
      "Epoch: 0020, Train Loss: 0.6226, Valid loss: 0.6679, Test loss: 0.6626\n",
      "Epoch: 0025, Train Loss: 0.5613, Valid loss: 0.6135, Test loss: 0.6097\n",
      "Epoch: 0030, Train Loss: 0.5113, Valid loss: 0.5717, Test loss: 0.5660\n",
      "Epoch: 0035, Train Loss: 0.4712, Valid loss: 0.5374, Test loss: 0.5322\n",
      "Epoch: 0040, Train Loss: 0.4373, Valid loss: 0.5087, Test loss: 0.5042\n",
      "Epoch: 0045, Train Loss: 0.4079, Valid loss: 0.4858, Test loss: 0.4816\n",
      "Epoch: 0050, Train Loss: 0.3829, Valid loss: 0.4645, Test loss: 0.4609\n",
      "Epoch: 0055, Train Loss: 0.3608, Valid loss: 0.4473, Test loss: 0.4433\n",
      "Epoch: 0060, Train Loss: 0.3415, Valid loss: 0.4322, Test loss: 0.4285\n",
      "Epoch: 0065, Train Loss: 0.3249, Valid loss: 0.4205, Test loss: 0.4172\n",
      "Epoch: 0070, Train Loss: 0.3097, Valid loss: 0.4102, Test loss: 0.4053\n",
      "Epoch: 0075, Train Loss: 0.2964, Valid loss: 0.4010, Test loss: 0.3960\n",
      "Epoch: 0080, Train Loss: 0.2834, Valid loss: 0.3923, Test loss: 0.3876\n",
      "Epoch: 0085, Train Loss: 0.2726, Valid loss: 0.3854, Test loss: 0.3798\n",
      "Epoch: 0090, Train Loss: 0.2618, Valid loss: 0.3796, Test loss: 0.3738\n",
      "Epoch: 0095, Train Loss: 0.2527, Valid loss: 0.3736, Test loss: 0.3684\n",
      "Epoch: 0100, Train Loss: 0.2440, Valid loss: 0.3691, Test loss: 0.3635\n",
      "Epoch: 0105, Train Loss: 0.2360, Valid loss: 0.3641, Test loss: 0.3586\n",
      "Epoch: 0110, Train Loss: 0.2285, Valid loss: 0.3605, Test loss: 0.3548\n",
      "Epoch: 0115, Train Loss: 0.2209, Valid loss: 0.3573, Test loss: 0.3512\n",
      "Epoch: 0120, Train Loss: 0.2141, Valid loss: 0.3560, Test loss: 0.3494\n",
      "Epoch: 0125, Train Loss: 0.2081, Valid loss: 0.3512, Test loss: 0.3457\n",
      "Epoch: 0130, Train Loss: 0.2016, Valid loss: 0.3493, Test loss: 0.3427\n",
      "Epoch: 0135, Train Loss: 0.1957, Valid loss: 0.3462, Test loss: 0.3398\n",
      "Epoch: 0140, Train Loss: 0.1912, Valid loss: 0.3458, Test loss: 0.3383\n",
      "Epoch: 0145, Train Loss: 0.1853, Valid loss: 0.3433, Test loss: 0.3370\n",
      "Epoch: 0150, Train Loss: 0.1813, Valid loss: 0.3439, Test loss: 0.3363\n",
      "Epoch: 0155, Train Loss: 0.1766, Valid loss: 0.3410, Test loss: 0.3336\n",
      "Epoch: 0160, Train Loss: 0.1721, Valid loss: 0.3425, Test loss: 0.3342\n",
      "Epoch: 0165, Train Loss: 0.1684, Valid loss: 0.3391, Test loss: 0.3319\n",
      "Epoch: 0170, Train Loss: 0.1639, Valid loss: 0.3412, Test loss: 0.3329\n",
      "Epoch: 0175, Train Loss: 0.1607, Valid loss: 0.3406, Test loss: 0.3322\n",
      "Epoch: 0180, Train Loss: 0.1568, Valid loss: 0.3392, Test loss: 0.3339\n",
      "Epoch: 0185, Train Loss: 0.1528, Valid loss: 0.3385, Test loss: 0.3331\n",
      "Epoch: 0190, Train Loss: 0.1499, Valid loss: 0.3387, Test loss: 0.3337\n",
      "Epoch: 0195, Train Loss: 0.1467, Valid loss: 0.3409, Test loss: 0.3357\n",
      "Epoch: 0200, Train Loss: 0.1444, Valid loss: 0.3396, Test loss: 0.3341\n",
      "Epoch: 0205, Train Loss: 0.1408, Valid loss: 0.3377, Test loss: 0.3334\n",
      "Epoch: 0210, Train Loss: 0.1379, Valid loss: 0.3392, Test loss: 0.3337\n",
      "Epoch: 0215, Train Loss: 0.1350, Valid loss: 0.3400, Test loss: 0.3345\n",
      "Epoch: 0220, Train Loss: 0.1330, Valid loss: 0.3394, Test loss: 0.3340\n",
      "Epoch: 0225, Train Loss: 0.1306, Valid loss: 0.3438, Test loss: 0.3370\n",
      "Epoch: 0230, Train Loss: 0.1278, Valid loss: 0.3415, Test loss: 0.3353\n",
      "Epoch: 0235, Train Loss: 0.1256, Valid loss: 0.3447, Test loss: 0.3391\n",
      "Epoch: 0240, Train Loss: 0.1230, Valid loss: 0.3448, Test loss: 0.3391\n",
      "Epoch: 0245, Train Loss: 0.1217, Valid loss: 0.3434, Test loss: 0.3388\n",
      "Epoch: 0250, Train Loss: 0.1195, Valid loss: 0.3455, Test loss: 0.3413\n",
      "Epoch: 0255, Train Loss: 0.1178, Valid loss: 0.3465, Test loss: 0.3415\n",
      "Epoch: 0260, Train Loss: 0.1160, Valid loss: 0.3478, Test loss: 0.3418\n",
      "Epoch: 0265, Train Loss: 0.1135, Valid loss: 0.3510, Test loss: 0.3454\n",
      "Epoch: 0270, Train Loss: 0.1119, Valid loss: 0.3519, Test loss: 0.3452\n",
      "Epoch: 0275, Train Loss: 0.1099, Valid loss: 0.3525, Test loss: 0.3457\n",
      "Epoch: 0280, Train Loss: 0.1079, Valid loss: 0.3553, Test loss: 0.3479\n",
      "Epoch: 0285, Train Loss: 0.1068, Valid loss: 0.3575, Test loss: 0.3498\n",
      "Epoch: 0290, Train Loss: 0.1050, Valid loss: 0.3581, Test loss: 0.3523\n",
      "Epoch: 0295, Train Loss: 0.1037, Valid loss: 0.3599, Test loss: 0.3521\n",
      "Epoch: 0300, Train Loss: 0.1017, Valid loss: 0.3599, Test loss: 0.3541\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1 + epochs):\n",
    "    loss = train(model, predictor, emb.weight, adj_t,\n",
    "                 optimizer, batch_size)\n",
    "    \n",
    "    if epoch % eval_steps == 0:\n",
    "        valid_loss, test_loss = test(model, predictor, emb.weight, adj_t, batch_size, \n",
    "                                     val_edges, test_edges, neg_val_edges, neg_test_edges)\n",
    "        save_models(model, predictor, emb, epoch)\n",
    "        print(f'Epoch: {epoch:04d}, '\n",
    "              f'Train Loss: {loss:.4f}, '\n",
    "              f'Valid loss: {valid_loss:.4f}, '\n",
    "              f'Test loss: {test_loss:.4f}')\n",
    "        losses = losses.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': loss,\n",
    "            'valid_loss': valid_loss.item(), \n",
    "            'test_loss': test_loss.item()\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.to_csv(f'../../data/results/graphsage_link_pred/{NB_NUMBER}_losses.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
