{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', \n",
    "                                 root='../data/dataset/',\n",
    "                                 transform=T.ToSparseTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(adj_t=[169343, 169343, nnz=2315598], node_year=[169343, 1], x=[169343, 128], y=[169343, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'][:, 0].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 3000\n",
    "epochs = 10000\n",
    "log_steps = 100\n",
    "input_dim = data['x'].shape[1]\n",
    "hidden_channels = input_dim * 2\n",
    "output_dim = data['y'][:, 0].unique().shape[0]\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_channels, output_dim):\n",
    "        super(OneLayer, self).__init__()\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        \n",
    "        \n",
    "        self.convs.append(SAGEConv(input_dim, output_dim))\n",
    "        \n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        x = self.convs[0](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneLayer(input_dim, hidden_channels, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 2.6279, Train: 26.40%, Valid: 25.30% Test: 22.93%\n",
      "Epoch: 200, Loss: 2.2587, Train: 40.51%, Valid: 42.20% Test: 40.24%\n",
      "Epoch: 300, Loss: 2.0079, Train: 48.94%, Valid: 50.53% Test: 49.19%\n",
      "Epoch: 400, Loss: 1.8331, Train: 53.56%, Valid: 54.93% Test: 53.74%\n",
      "Epoch: 500, Loss: 1.7074, Train: 56.07%, Valid: 57.08% Test: 56.16%\n",
      "Epoch: 600, Loss: 1.6141, Train: 57.65%, Valid: 58.39% Test: 57.54%\n",
      "Epoch: 700, Loss: 1.5425, Train: 58.79%, Valid: 59.40% Test: 58.48%\n",
      "Epoch: 800, Loss: 1.4862, Train: 59.67%, Valid: 60.18% Test: 59.26%\n",
      "Epoch: 900, Loss: 1.4409, Train: 60.38%, Valid: 60.85% Test: 59.90%\n",
      "Epoch: 1000, Loss: 1.4037, Train: 60.91%, Valid: 61.46% Test: 60.37%\n",
      "Epoch: 1100, Loss: 1.3728, Train: 61.38%, Valid: 61.99% Test: 60.79%\n",
      "Epoch: 1200, Loss: 1.3466, Train: 61.82%, Valid: 62.38% Test: 61.17%\n",
      "Epoch: 1300, Loss: 1.3242, Train: 62.20%, Valid: 62.68% Test: 61.39%\n",
      "Epoch: 1400, Loss: 1.3048, Train: 62.58%, Valid: 62.99% Test: 61.65%\n",
      "Epoch: 1500, Loss: 1.2878, Train: 62.89%, Valid: 63.24% Test: 61.90%\n",
      "Epoch: 1600, Loss: 1.2729, Train: 63.20%, Valid: 63.40% Test: 62.13%\n",
      "Epoch: 1700, Loss: 1.2596, Train: 63.46%, Valid: 63.61% Test: 62.36%\n",
      "Epoch: 1800, Loss: 1.2477, Train: 63.67%, Valid: 63.70% Test: 62.56%\n",
      "Epoch: 1900, Loss: 1.2370, Train: 63.88%, Valid: 63.84% Test: 62.75%\n",
      "Epoch: 2000, Loss: 1.2273, Train: 64.07%, Valid: 63.97% Test: 62.92%\n",
      "Epoch: 2100, Loss: 1.2185, Train: 64.30%, Valid: 64.06% Test: 63.06%\n",
      "Epoch: 2200, Loss: 1.2104, Train: 64.47%, Valid: 64.21% Test: 63.18%\n",
      "Epoch: 2300, Loss: 1.2030, Train: 64.62%, Valid: 64.30% Test: 63.32%\n",
      "Epoch: 2400, Loss: 1.1961, Train: 64.76%, Valid: 64.42% Test: 63.42%\n",
      "Epoch: 2500, Loss: 1.1898, Train: 64.91%, Valid: 64.48% Test: 63.53%\n",
      "Epoch: 2600, Loss: 1.1839, Train: 65.06%, Valid: 64.55% Test: 63.64%\n",
      "Epoch: 2700, Loss: 1.1784, Train: 65.20%, Valid: 64.59% Test: 63.73%\n",
      "Epoch: 2800, Loss: 1.1733, Train: 65.34%, Valid: 64.60% Test: 63.83%\n",
      "Epoch: 2900, Loss: 1.1685, Train: 65.44%, Valid: 64.67% Test: 63.86%\n",
      "Epoch: 3000, Loss: 1.1640, Train: 65.55%, Valid: 64.68% Test: 63.95%\n",
      "Epoch: 3100, Loss: 1.1598, Train: 65.62%, Valid: 64.73% Test: 63.98%\n",
      "Epoch: 3200, Loss: 1.1558, Train: 65.73%, Valid: 64.80% Test: 64.05%\n",
      "Epoch: 3300, Loss: 1.1521, Train: 65.85%, Valid: 64.81% Test: 64.10%\n",
      "Epoch: 3400, Loss: 1.1485, Train: 65.93%, Valid: 64.88% Test: 64.17%\n",
      "Epoch: 3500, Loss: 1.1452, Train: 66.03%, Valid: 64.94% Test: 64.22%\n",
      "Epoch: 3600, Loss: 1.1420, Train: 66.10%, Valid: 64.99% Test: 64.30%\n",
      "Epoch: 3700, Loss: 1.1390, Train: 66.18%, Valid: 65.03% Test: 64.37%\n",
      "Epoch: 3800, Loss: 1.1361, Train: 66.24%, Valid: 65.03% Test: 64.40%\n",
      "Epoch: 3900, Loss: 1.1334, Train: 66.32%, Valid: 65.04% Test: 64.44%\n",
      "Epoch: 4000, Loss: 1.1308, Train: 66.39%, Valid: 65.06% Test: 64.51%\n",
      "Epoch: 4100, Loss: 1.1284, Train: 66.46%, Valid: 65.09% Test: 64.56%\n",
      "Epoch: 4200, Loss: 1.1261, Train: 66.49%, Valid: 65.15% Test: 64.61%\n",
      "Epoch: 4300, Loss: 1.1238, Train: 66.58%, Valid: 65.16% Test: 64.62%\n",
      "Epoch: 4400, Loss: 1.1217, Train: 66.63%, Valid: 65.20% Test: 64.63%\n",
      "Epoch: 4500, Loss: 1.1197, Train: 66.69%, Valid: 65.26% Test: 64.67%\n",
      "Epoch: 4600, Loss: 1.1178, Train: 66.77%, Valid: 65.25% Test: 64.66%\n",
      "Epoch: 4700, Loss: 1.1159, Train: 66.81%, Valid: 65.32% Test: 64.72%\n",
      "Epoch: 4800, Loss: 1.1142, Train: 66.86%, Valid: 65.38% Test: 64.76%\n",
      "Epoch: 4900, Loss: 1.1125, Train: 66.86%, Valid: 65.41% Test: 64.77%\n",
      "Epoch: 5000, Loss: 1.1109, Train: 66.90%, Valid: 65.43% Test: 64.80%\n",
      "Epoch: 5100, Loss: 1.1094, Train: 66.92%, Valid: 65.44% Test: 64.85%\n",
      "Epoch: 5200, Loss: 1.1080, Train: 66.95%, Valid: 65.44% Test: 64.86%\n",
      "Epoch: 5300, Loss: 1.1066, Train: 67.03%, Valid: 65.41% Test: 64.87%\n",
      "Epoch: 5400, Loss: 1.1053, Train: 67.06%, Valid: 65.43% Test: 64.89%\n",
      "Epoch: 5500, Loss: 1.1040, Train: 67.06%, Valid: 65.44% Test: 64.87%\n",
      "Epoch: 5600, Loss: 1.1028, Train: 67.09%, Valid: 65.44% Test: 64.87%\n",
      "Epoch: 5700, Loss: 1.1017, Train: 67.09%, Valid: 65.40% Test: 64.88%\n",
      "Epoch: 5800, Loss: 1.1006, Train: 67.11%, Valid: 65.40% Test: 64.88%\n",
      "Epoch: 5900, Loss: 1.0995, Train: 67.12%, Valid: 65.43% Test: 64.91%\n",
      "Epoch: 6000, Loss: 1.0985, Train: 67.17%, Valid: 65.45% Test: 64.90%\n",
      "Epoch: 6100, Loss: 1.0976, Train: 67.18%, Valid: 65.47% Test: 64.90%\n",
      "Epoch: 6200, Loss: 1.0967, Train: 67.20%, Valid: 65.50% Test: 64.91%\n",
      "Epoch: 6300, Loss: 1.0958, Train: 67.22%, Valid: 65.48% Test: 64.90%\n",
      "Epoch: 6400, Loss: 1.0950, Train: 67.22%, Valid: 65.50% Test: 64.88%\n",
      "Epoch: 6500, Loss: 1.0942, Train: 67.25%, Valid: 65.50% Test: 64.90%\n",
      "Epoch: 6600, Loss: 1.0934, Train: 67.27%, Valid: 65.52% Test: 64.90%\n",
      "Epoch: 6700, Loss: 1.0927, Train: 67.29%, Valid: 65.50% Test: 64.89%\n",
      "Epoch: 6800, Loss: 1.0920, Train: 67.31%, Valid: 65.53% Test: 64.87%\n",
      "Epoch: 6900, Loss: 1.0914, Train: 67.32%, Valid: 65.52% Test: 64.90%\n",
      "Epoch: 7000, Loss: 1.0908, Train: 67.35%, Valid: 65.52% Test: 64.88%\n",
      "Epoch: 7100, Loss: 1.0902, Train: 67.38%, Valid: 65.56% Test: 64.89%\n",
      "Epoch: 7200, Loss: 1.0896, Train: 67.39%, Valid: 65.57% Test: 64.90%\n",
      "Epoch: 7300, Loss: 1.0891, Train: 67.40%, Valid: 65.54% Test: 64.90%\n",
      "Epoch: 7400, Loss: 1.0886, Train: 67.41%, Valid: 65.52% Test: 64.88%\n",
      "Epoch: 7500, Loss: 1.0881, Train: 67.42%, Valid: 65.51% Test: 64.87%\n",
      "Epoch: 7600, Loss: 1.0876, Train: 67.42%, Valid: 65.53% Test: 64.86%\n",
      "Epoch: 7700, Loss: 1.0872, Train: 67.43%, Valid: 65.52% Test: 64.87%\n",
      "Epoch: 7800, Loss: 1.0867, Train: 67.44%, Valid: 65.53% Test: 64.87%\n",
      "Epoch: 7900, Loss: 1.0863, Train: 67.44%, Valid: 65.51% Test: 64.86%\n",
      "Epoch: 8000, Loss: 1.0860, Train: 67.44%, Valid: 65.49% Test: 64.88%\n",
      "Epoch: 8100, Loss: 1.0856, Train: 67.45%, Valid: 65.53% Test: 64.88%\n",
      "Epoch: 8200, Loss: 1.0853, Train: 67.45%, Valid: 65.51% Test: 64.90%\n",
      "Epoch: 8300, Loss: 1.0849, Train: 67.47%, Valid: 65.52% Test: 64.92%\n",
      "Epoch: 8400, Loss: 1.0846, Train: 67.47%, Valid: 65.49% Test: 64.91%\n",
      "Epoch: 8500, Loss: 1.0843, Train: 67.48%, Valid: 65.51% Test: 64.90%\n",
      "Epoch: 8600, Loss: 1.0841, Train: 67.48%, Valid: 65.50% Test: 64.91%\n",
      "Epoch: 8700, Loss: 1.0838, Train: 67.49%, Valid: 65.51% Test: 64.90%\n",
      "Epoch: 8800, Loss: 1.0836, Train: 67.51%, Valid: 65.51% Test: 64.88%\n",
      "Epoch: 8900, Loss: 1.0833, Train: 67.52%, Valid: 65.51% Test: 64.89%\n",
      "Epoch: 9000, Loss: 1.0831, Train: 67.52%, Valid: 65.52% Test: 64.87%\n",
      "Epoch: 9100, Loss: 1.0829, Train: 67.53%, Valid: 65.52% Test: 64.88%\n",
      "Epoch: 9200, Loss: 1.0827, Train: 67.54%, Valid: 65.51% Test: 64.91%\n",
      "Epoch: 9300, Loss: 1.0825, Train: 67.56%, Valid: 65.52% Test: 64.90%\n",
      "Epoch: 9400, Loss: 1.0823, Train: 67.57%, Valid: 65.52% Test: 64.91%\n",
      "Epoch: 9500, Loss: 1.0822, Train: 67.57%, Valid: 65.52% Test: 64.90%\n",
      "Epoch: 9600, Loss: 1.0820, Train: 67.58%, Valid: 65.52% Test: 64.89%\n",
      "Epoch: 9700, Loss: 1.0818, Train: 67.59%, Valid: 65.53% Test: 64.88%\n",
      "Epoch: 9800, Loss: 1.0817, Train: 67.60%, Valid: 65.53% Test: 64.89%\n",
      "Epoch: 9900, Loss: 1.0816, Train: 67.61%, Valid: 65.52% Test: 64.88%\n",
      "Epoch: 10000, Loss: 1.0814, Train: 67.60%, Valid: 65.53% Test: 64.90%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "for epoch in range(1, 1 + epochs):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        train_acc, valid_acc, test_acc = result\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_acc:.2f}%, '\n",
    "              f'Valid: {100 * valid_acc:.2f}% '\n",
    "              f'Test: {100 * test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
